{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef927a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_path = \"Datasets/images/train/02.jpg\"\n",
    "\n",
    "def preprocess_cin(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Niveaux de gris\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # AmÃ©lioration contraste (CLAHE)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    contrast = clahe.apply(gray)\n",
    "\n",
    "    # Binarisation adaptative\n",
    "    binary = cv2.adaptiveThreshold(contrast, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # RÃ©duction bruit\n",
    "    denoised = cv2.bilateralFilter(binary, 9, 75, 75)\n",
    "\n",
    "    return denoised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a776226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.228 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.222 ğŸš€ Python-3.11.9 torch-2.1.2+cu118 CPU (Intel Core(TM) i7-6700HQ 2.60GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/marco/Projet_du_Fin_DEtude_M2/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train34, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train34, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 182.2Â±125.8 MB/s, size: 350.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/labels/train... 24 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 658.8it/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 352.7Â±211.1 MB/s, size: 713.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/labels/val... 2 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 613.8it/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/labels/val.cache\n",
      "Plotting labels to /home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train34/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train34\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100         0G      2.324      3.264      2.216         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.2it/s 11.5s12.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          2          2    0.00333          1      0.695      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100         0G      2.214      3.423      2.096         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.2it/s 11.1s11.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          2          2    0.00333          1      0.828      0.241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100         0G      2.163      3.368      2.129         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.2it/s 10.7s11.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.3s\n",
      "                   all          2          2    0.00333          1      0.995       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100         0G      1.739      3.022      1.771         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.2it/s 10.5s11.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
      "                   all          2          2    0.00333          1      0.995      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100         0G      1.691      2.864      1.681         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.2it/s 10.8s11.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.3s\n",
      "                   all          2          2    0.00333          1      0.828      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100         0G      1.354      2.306      1.467         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.2it/s 10.7s12.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          2          2    0.00333          1      0.995      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100         0G      1.354      2.252      1.413         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0.2it/s 10.8s11.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.3s\n",
      "                   all          2          2    0.00333          1      0.828      0.369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100         0G      1.291      1.953      1.299         37        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 1/2 0.1it/s 10.9s<12.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolov8n.pt\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# version nano = rapide\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# EntraÃ®ner\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/marco/Projet_du_Fin_DEtude_M2/data.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/marco/lib/python3.11/site-packages/ultralytics/engine/model.py:800\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/marco/lib/python3.11/site-packages/ultralytics/engine/trainer.py:240\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    237\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/marco/lib/python3.11/site-packages/ultralytics/engine/trainer.py:431\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    428\u001b[39m     \u001b[38;5;28mself\u001b[39m.tloss = \u001b[38;5;28mself\u001b[39m.loss_items \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.tloss * i + \u001b[38;5;28mself\u001b[39m.loss_items) / (i + \u001b[32m1\u001b[39m)\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m    433\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/marco/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    484\u001b[39m         Tensor.backward,\n\u001b[32m    485\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m         inputs=inputs,\n\u001b[32m    491\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/marco/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    246\u001b[39m     retain_graph = create_graph\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger un modÃ¨le prÃ©-entraÃ®nÃ©\n",
    "model = YOLO(\"yolov8n.pt\")  # version nano = rapide\n",
    "\n",
    "# EntraÃ®ner\n",
    "model.train(data=\"/home/marco/Projet_du_Fin_DEtude_M2/data.yaml\", epochs=100, imgsz=640, batch=16, device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8324be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228 ğŸš€ Python-3.11.9 torch-2.1.2+cu118 CUDA:0 (NVIDIA GeForce GTX 1060, 6066MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/marco/Projet_du_Fin_DEtude_M2/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train35, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train35, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/marco/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 185.5Â±116.1 MB/s, size: 350.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/labels/train.cache... 24 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 38.8Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 217.9Â±167.4 MB/s, size: 713.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/labels/val.cache... 2 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 758.1it/s 0.0ss\n",
      "Plotting labels to /home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train35/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train35\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      2.13G      2.166      3.392      2.122         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.8it/s 0.1s\n",
      "                   all          2          2    0.00333          1      0.638        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      2.13G      2.126      3.421       2.09         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.1it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.7it/s 0.0s\n",
      "                   all          2          2    0.00333          1       0.62      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      2.13G      2.148      3.367      2.151         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.6it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.695      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      2.15G      2.008      3.153      1.934         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.9it/s 0.7s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.1it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.745      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      2.15G      1.809      3.193      1.829         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.6it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.995      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      2.15G      1.526      2.667      1.602         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.4it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.995      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      2.15G      1.422      2.269      1.524         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.8it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.828      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      2.15G      1.439      2.347      1.468         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.1it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.1it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.663       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      2.15G      1.265       1.81      1.294         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 31.9it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.663      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      2.16G      1.224      1.905      1.303         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.1it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.828      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      2.16G      1.224      1.742      1.256         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 23.4it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.828      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      2.16G      1.149      1.645      1.293         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.5it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.828      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      2.16G      1.081      1.541      1.138         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.4it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.828      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      2.16G       1.05      1.517      1.114         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.0it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.995      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      2.16G     0.9955      1.457      1.154         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.0it/s 0.0s\n",
      "                   all          2          2    0.00333          1      0.995      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      2.16G      1.064      1.324      1.195         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.2it/s 0.0s\n",
      "                   all          2          2     0.0385          1      0.995      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      2.16G      0.986      1.366      1.153         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.8it/s 0.0s\n",
      "                   all          2          2      0.867          1      0.995      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      2.16G     0.9486      1.758      1.107         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.6it/s 0.0s\n",
      "                   all          2          2       0.88          1      0.995      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      2.16G     0.9726      1.394      1.124         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.3it/s 0.0s\n",
      "                   all          2          2       0.93          1      0.995      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      2.16G     0.9316      1.179      1.056         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.3it/s 0.0s\n",
      "                   all          2          2      0.938          1      0.995      0.654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      2.16G     0.9211      1.341      1.188         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.3it/s 0.0s\n",
      "                   all          2          2      0.956          1      0.995      0.697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      2.16G     0.8677      1.157      1.085         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.8it/s 0.0s\n",
      "                   all          2          2       0.97          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      2.16G      0.895      1.293      1.091         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.6it/s 0.0s\n",
      "                   all          2          2      0.972          1      0.995      0.846\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      2.16G     0.9043      1.221      1.039         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.9it/s 0.0s\n",
      "                   all          2          2       0.97          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      2.16G      1.011      1.353      1.155         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.4it/s 0.0s\n",
      "                   all          2          2      0.964          1      0.995      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      2.16G      0.894      1.125      1.047         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 17.2it/s 0.1s\n",
      "                   all          2          2       0.96          1      0.995      0.757\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      2.16G     0.8103      1.107     0.9885         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 30.3it/s 0.0s\n",
      "                   all          2          2       0.98          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      2.16G     0.8838      1.065      1.032         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.5it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.7it/s 0.0s\n",
      "                   all          2          2       0.98          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      2.16G     0.8637      1.068      1.086         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.2it/s 0.0s\n",
      "                   all          2          2      0.981          1      0.995      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      2.16G     0.8164      1.162      1.014         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.2it/s 0.0s\n",
      "                   all          2          2      0.978          1      0.995      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      2.16G     0.8731      1.146       1.09         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 30.4it/s 0.0s\n",
      "                   all          2          2      0.978          1      0.995      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      2.16G     0.7443      1.176      1.035         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.2it/s 0.0s\n",
      "                   all          2          2      0.981          1      0.995      0.671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      2.16G     0.7854      1.071      1.024         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.3it/s 0.0s\n",
      "                   all          2          2      0.852          1      0.995      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      2.16G     0.8104      1.071      1.031         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 31.6it/s 0.0s\n",
      "                   all          2          2      0.852          1      0.995      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      2.16G      0.809      1.161     0.9895         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.8it/s 0.0s\n",
      "                   all          2          2      0.915          1      0.995      0.697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      2.16G       0.78      1.012     0.9594         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.2it/s 0.0s\n",
      "                   all          2          2       0.97          1      0.995       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      2.16G     0.7444      1.015     0.9941         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.3it/s 0.0s\n",
      "                   all          2          2       0.97          1      0.995       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      2.16G     0.7171     0.9966      1.007         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.0it/s 0.0s\n",
      "                   all          2          2      0.977          1      0.995      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      2.16G     0.8106      1.123      1.063         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 30.2it/s 0.0s\n",
      "                   all          2          2      0.983          1      0.995      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      2.16G     0.7673     0.9522      1.033         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 31.2it/s 0.0s\n",
      "                   all          2          2      0.983          1      0.995      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      2.16G      0.751     0.9925      1.018         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.8it/s 0.0s\n",
      "                   all          2          2       0.93          1      0.995      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      2.16G     0.7478     0.8959     0.9677         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.3it/s 0.0s\n",
      "                   all          2          2      0.946          1      0.995      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      2.16G     0.7693     0.9082      1.012         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 31.0it/s 0.0s\n",
      "                   all          2          2      0.946          1      0.995      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      2.16G     0.7765     0.9724      1.069         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 25.6it/s 0.0s\n",
      "                   all          2          2      0.981          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      2.16G      0.858      0.992      1.065         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.9it/s 0.0s\n",
      "                   all          2          2      0.981          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      2.16G     0.9191     0.9844        1.1         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.4it/s 0.0s\n",
      "                   all          2          2      0.982          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      2.16G     0.6726      0.868     0.9858         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.1it/s 0.0s\n",
      "                   all          2          2      0.982          1      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      2.16G     0.6997      0.911     0.9517         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.0it/s 0.0s\n",
      "                   all          2          2          1      0.994      0.995      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      2.16G     0.6919      0.844     0.9452         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.4it/s 0.0s\n",
      "                   all          2          2          1      0.994      0.995      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      2.16G     0.7415     0.8991       0.99         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.8it/s 0.0s\n",
      "                   all          2          2          1      0.966      0.995      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      2.16G     0.7375      0.879       1.08         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 25.8it/s 0.0s\n",
      "                   all          2          2          1      0.966      0.995      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      2.16G     0.7659     0.8925      1.003         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.7it/s 0.0s\n",
      "                   all          2          2      0.634          1      0.828       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      2.16G     0.6747     0.8186     0.9448         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 25.9it/s 0.0s\n",
      "                   all          2          2      0.634          1      0.828       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      2.16G     0.7387     0.9062      1.011         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.4it/s 0.0s\n",
      "                   all          2          2      0.621      0.864      0.828       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      2.16G     0.6973     0.8609     0.9963         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.5it/s 0.0s\n",
      "                   all          2          2      0.621      0.864      0.828       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      2.16G     0.7046     0.7757     0.9502         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 24.6it/s 0.0s\n",
      "                   all          2          2      0.966        0.5      0.595      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      2.16G     0.6305     0.7755     0.9388         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.2it/s 0.0s\n",
      "                   all          2          2      0.966        0.5      0.595      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      2.16G     0.6357     0.8562     0.9771         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.0it/s 0.0s\n",
      "                   all          2          2       0.95        0.5      0.606       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      2.16G     0.7648     0.8295     0.9685         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.8it/s 0.0s\n",
      "                   all          2          2       0.95        0.5      0.606       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      2.16G     0.5992     0.6909     0.9137         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.8it/s 0.0s\n",
      "                   all          2          2       0.93        0.5      0.595      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      2.16G      0.711     0.8191     0.9641         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.5it/s 0.1s\n",
      "                   all          2          2       0.93        0.5      0.595      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      2.16G     0.6536     0.7618     0.9266         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 30.0it/s 0.0s\n",
      "                   all          2          2        0.9        0.5      0.572      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      2.16G       0.59     0.7593      0.925         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.5it/s 0.0s\n",
      "                   all          2          2        0.9        0.5      0.572      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      2.16G     0.6607     0.8559     0.9261         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.4it/s 0.0s\n",
      "                   all          2          2      0.901        0.5      0.524      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      2.16G     0.6296     0.7789     0.9322         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.3it/s 0.0s\n",
      "                   all          2          2      0.901        0.5      0.524      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      2.16G     0.5683     0.7679     0.9352         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 30.6it/s 0.0s\n",
      "                   all          2          2      0.944        0.5      0.509      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      2.16G     0.5992     0.7404     0.9325         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.5it/s 0.0s\n",
      "                   all          2          2      0.944        0.5      0.509      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      2.16G      0.586     0.8223     0.9245         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.9it/s 0.0s\n",
      "                   all          2          2      0.947        0.5      0.504      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      2.16G     0.5745     0.7273     0.9339         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.3it/s 0.0s\n",
      "                   all          2          2      0.947        0.5      0.504      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      2.16G      0.527     0.7026     0.9176         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 30.8it/s 0.0s\n",
      "                   all          2          2      0.955        0.5      0.503      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      2.16G     0.4822     0.6681     0.8673         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.6it/s 0.0s\n",
      "                   all          2          2      0.955        0.5      0.503      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      2.16G     0.6034      0.749      0.941         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.6it/s 0.0s\n",
      "                   all          2          2      0.994          1      0.995      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      2.16G       0.65     0.9309     0.9646         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.3it/s 0.0s\n",
      "                   all          2          2      0.994          1      0.995      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      2.16G     0.7179     0.7727     0.9891         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.8it/s 0.0s\n",
      "                   all          2          2      0.989          1      0.995      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      2.16G      0.589     0.7896     0.9344         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.0it/s 0.0s\n",
      "                   all          2          2      0.989          1      0.995      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      2.16G     0.4625     0.6396     0.8917         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.4it/s 0.0s\n",
      "                   all          2          2      0.986          1      0.995      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      2.16G     0.5813     0.7754     0.9443         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.4it/s 0.0s\n",
      "                   all          2          2      0.986          1      0.995      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      2.16G     0.5528     0.6441     0.8895         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.5it/s 0.0s\n",
      "                   all          2          2      0.986          1      0.995       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      2.16G      0.592     0.6599      0.917         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.4it/s 0.0s\n",
      "                   all          2          2      0.986          1      0.995       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      2.16G     0.5926     0.8022      0.938         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.6it/s 0.0s\n",
      "                   all          2          2      0.986          1      0.995      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      2.16G     0.5322     0.6693     0.8672         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.9it/s 0.0s\n",
      "                   all          2          2      0.986          1      0.995      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      2.16G     0.5764     0.6929     0.9371         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.7it/s 0.0s\n",
      "                   all          2          2      0.988          1      0.995      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      2.16G     0.5753     0.7725     0.9311         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.4it/s 0.0s\n",
      "                   all          2          2      0.988          1      0.995      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      2.16G     0.5182     0.6672     0.8945         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 25.5it/s 0.0s\n",
      "                   all          2          2      0.989          1      0.995      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      2.16G     0.5152     0.6314     0.9358         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.7it/s 0.0s\n",
      "                   all          2          2      0.989          1      0.995      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      2.16G     0.4975     0.6368     0.8731         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 29.7it/s 0.0s\n",
      "                   all          2          2      0.989          1      0.995      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      2.16G     0.5013     0.6263      0.911         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.8it/s 0.0s\n",
      "                   all          2          2      0.989          1      0.995      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      2.16G     0.5402      0.645     0.9174         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 31.2it/s 0.0s\n",
      "                   all          2          2      0.987          1      0.995      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      2.16G     0.5383     0.6917     0.9021         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 22.1it/s 0.0s\n",
      "                   all          2          2      0.987          1      0.995      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      2.16G     0.5803     0.6411     0.9177         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.0it/s 0.0s\n",
      "                   all          2          2      0.986          1      0.995      0.555\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      2.16G     0.3424     0.8775     0.8716          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.7it/s 0.1s\n",
      "                   all          2          2      0.986          1      0.995      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      2.16G     0.3688     0.8433     0.8448          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.5it/s 0.8s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.2it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      2.16G     0.3979     0.8264     0.9019          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 23.3it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      2.16G     0.3805     0.8022     0.8615          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 31.8it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      2.16G     0.4353     0.8362     0.8393          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 27.4it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      2.16G     0.4574     0.8708     0.8977          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.5it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      2.16G     0.3912     0.7633     0.8552          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 26.0it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      2.16G     0.3345     0.7004     0.8154          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 28.5it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      2.16G     0.3513     0.7294     0.8877          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.4it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 31.8it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      2.16G     0.3556     0.7416     0.8595          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.3it/s 0.6s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.1it/s 0.0s\n",
      "                   all          2          2      0.984          1      0.995      0.496\n",
      "\n",
      "100 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from /home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train35/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train35/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train35/weights/best.pt...\n",
      "Ultralytics 8.3.228 ğŸš€ Python-3.11.9 torch-2.1.2+cu118 CUDA:0 (NVIDIA GeForce GTX 1060, 6066MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 37.5it/s 0.0s\n",
      "                   all          2          2      0.972          1      0.995      0.846\n",
      "Speed: 0.4ms preprocess, 7.5ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train35\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7efd5ba4edd0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0066445,   0.0066445,   0.0066445,   0.0066445,    0.022605,    0.022638,    0.022671,    0.022704,    0.022846,    0.026546,    0.043013,    0.084246,     0.14299,     0.19651,      0.2413,     0.27943,      0.3113,     0.31995,     0.32852,     0.36703,     0.39029,     0.40804,     0.42185,\n",
       "            0.43543,     0.46476,     0.50489,     0.51664,      0.5282,     0.53958,     0.55078,     0.56182,     0.57193,     0.57619,     0.58042,     0.58463,     0.58881,     0.59297,      0.5971,     0.60122,      0.6053,     0.60936,      0.6134,     0.61742,     0.62141,     0.62538,     0.62933,\n",
       "            0.63325,     0.63715,     0.64103,     0.64489,     0.64872,     0.65254,     0.65633,      0.6601,     0.66385,     0.67352,     0.70075,     0.72688,     0.75199,     0.77612,     0.79934,     0.80041,     0.80084,     0.80126,     0.80169,     0.80211,     0.80253,     0.80296,     0.80338,\n",
       "             0.8038,     0.80423,     0.80465,     0.80507,     0.80549,     0.80591,     0.80633,     0.80675,     0.80717,     0.80759,     0.80801,     0.80843,     0.80885,     0.80927,     0.80969,     0.81011,     0.81053,     0.81094,     0.81136,     0.81178,      0.8122,     0.81261,     0.81303,\n",
       "            0.81344,     0.81386,     0.81428,     0.81469,      0.8151,     0.81552,     0.81593,     0.81635,     0.81676,     0.81717,     0.81759,       0.818,     0.81841,     0.81882,     0.81924,     0.81965,     0.82006,     0.82047,     0.82088,     0.82129,      0.8217,     0.82211,     0.82252,\n",
       "            0.82293,     0.82334,     0.82375,     0.82416,     0.82457,     0.82497,     0.82538,     0.82579,      0.8262,      0.8266,     0.82701,     0.82741,     0.82782,     0.82823,     0.82863,     0.82904,     0.82944,     0.82985,     0.83025,     0.83065,     0.83106,     0.83146,     0.83186,\n",
       "            0.83227,     0.83267,     0.83307,     0.83347,     0.83388,     0.83428,     0.83468,     0.83508,     0.83548,     0.83588,     0.83628,     0.83668,     0.83708,     0.83748,     0.83788,     0.83828,     0.83868,     0.83907,     0.83947,     0.83987,     0.84027,     0.84066,     0.84106,\n",
       "            0.84146,     0.84185,     0.84225,     0.84264,     0.84304,     0.84344,     0.84383,     0.84422,     0.84462,     0.84501,     0.84541,      0.8458,     0.84619,     0.84659,     0.84698,     0.84737,     0.84776,     0.84816,     0.84855,     0.84894,     0.84933,     0.84972,     0.85011,\n",
       "             0.8505,     0.85089,     0.85128,     0.85167,     0.85206,     0.85245,     0.85284,     0.85323,     0.85362,       0.854,     0.85439,     0.85478,     0.85517,     0.85555,     0.85594,     0.85633,     0.85671,      0.8571,     0.85748,     0.85787,     0.85825,     0.85864,     0.85902,\n",
       "            0.85941,     0.85979,     0.86018,     0.86056,     0.86094,     0.86133,     0.86171,     0.86209,     0.86247,     0.86286,     0.86324,     0.86362,       0.864,     0.86438,     0.86476,     0.86514,     0.86552,      0.8659,     0.86628,     0.86666,     0.86704,     0.86742,      0.8678,\n",
       "            0.86818,     0.86856,     0.86893,     0.86931,     0.86969,     0.87007,     0.87044,     0.87082,      0.8712,     0.87157,     0.87195,     0.87232,      0.8727,     0.87307,     0.87345,     0.87382,      0.8742,     0.87457,     0.87495,     0.87532,     0.87569,     0.87607,     0.87644,\n",
       "            0.87681,     0.87718,     0.87756,     0.87793,      0.8783,     0.87867,     0.87904,     0.87941,     0.87978,     0.88016,     0.88053,      0.8809,     0.88127,     0.88163,       0.882,     0.88237,     0.88274,     0.88311,     0.88348,     0.88385,     0.88421,     0.88458,     0.88495,\n",
       "            0.88532,     0.88568,     0.88605,     0.88642,     0.88678,     0.88715,     0.88751,     0.88788,     0.88824,     0.88861,     0.88897,     0.88934,      0.8897,     0.89007,     0.89043,     0.89079,     0.89116,     0.89152,     0.89188,     0.89224,     0.89261,     0.89297,     0.89333,\n",
       "            0.89369,     0.89405,     0.89442,     0.89478,     0.89514,      0.8955,     0.89586,     0.89622,     0.89658,     0.89694,      0.8973,     0.89765,     0.89801,     0.89837,     0.89873,     0.89909,     0.89945,      0.8998,     0.90016,     0.90052,     0.90087,     0.90123,     0.90159,\n",
       "            0.90194,      0.9023,     0.90266,     0.90301,     0.90337,     0.90372,     0.90408,     0.90443,     0.90479,     0.90514,     0.90549,     0.90585,      0.9062,     0.90655,     0.90691,     0.90726,     0.90761,     0.90796,     0.90832,     0.90867,     0.90902,     0.90937,     0.90972,\n",
       "            0.91007,     0.91042,     0.91077,     0.91112,     0.91147,     0.91182,     0.91217,     0.91252,     0.91287,     0.91322,     0.91357,     0.91392,     0.91427,     0.91462,     0.91496,     0.91531,     0.91566,     0.91601,     0.91635,      0.9167,     0.91705,     0.91739,     0.91774,\n",
       "            0.91808,     0.91843,     0.91877,     0.91912,     0.91946,     0.91981,     0.92015,      0.9205,     0.92084,     0.92119,     0.92153,     0.92187,     0.92222,     0.92256,      0.9229,     0.92324,     0.92359,     0.92393,     0.92427,     0.92461,     0.92495,     0.92529,     0.92564,\n",
       "            0.92598,     0.92632,     0.92666,       0.927,     0.92734,     0.92768,     0.92802,     0.92836,     0.92869,     0.92903,     0.92937,     0.92971,     0.93005,     0.93039,     0.93072,     0.93106,      0.9314,     0.93174,     0.93207,     0.93241,     0.93275,     0.93308,     0.93342,\n",
       "            0.93375,     0.93409,     0.93443,     0.93476,      0.9351,     0.93543,     0.93577,      0.9361,     0.93643,     0.93677,      0.9371,     0.93744,     0.93777,      0.9381,     0.93843,     0.93877,      0.9391,     0.93943,     0.93976,      0.9401,     0.94043,     0.94076,     0.94109,\n",
       "            0.94142,     0.94175,     0.94208,     0.94241,     0.94274,     0.94307,      0.9434,     0.94373,     0.94406,     0.94439,     0.94472,     0.94505,     0.94538,     0.94571,     0.94603,     0.94636,     0.94669,     0.94702,     0.94735,     0.94767,       0.948,     0.94833,     0.94865,\n",
       "            0.94898,      0.9493,     0.94963,     0.94996,     0.95028,     0.95061,     0.95093,     0.95126,     0.95158,     0.95191,     0.95223,     0.95256,     0.95288,      0.9532,     0.95353,     0.95385,     0.95417,      0.9545,     0.95482,     0.95514,     0.95546,     0.95579,     0.95611,\n",
       "            0.95643,     0.95675,     0.95707,     0.95739,     0.95771,     0.95803,     0.95836,     0.95868,       0.959,     0.95932,     0.95964,     0.95995,     0.96027,     0.96059,     0.96091,     0.96123,     0.96155,     0.96187,     0.96219,      0.9625,     0.96282,     0.96314,     0.96346,\n",
       "            0.96377,     0.96409,     0.96441,     0.96472,     0.96504,     0.96536,     0.96567,     0.96599,      0.9663,     0.96662,     0.96694,     0.96725,     0.96757,     0.96788,     0.96819,     0.96851,     0.96882,     0.96914,     0.96945,     0.96976,     0.97008,     0.97039,      0.9707,\n",
       "            0.97102,     0.97133,     0.97164,     0.97195,     0.97227,     0.97258,     0.97289,      0.9732,     0.97351,     0.97382,     0.97413,     0.97444,     0.97476,     0.97507,     0.97538,     0.97569,       0.976,     0.97631,     0.97661,     0.97692,     0.97723,     0.97754,     0.97785,\n",
       "            0.97816,     0.97847,     0.97878,     0.97908,     0.97939,      0.9797,     0.98001,     0.98031,     0.98062,     0.98093,     0.98123,     0.98154,     0.98185,     0.98215,     0.98246,     0.98276,     0.98307,     0.98337,     0.98368,     0.98398,     0.98429,     0.98459,      0.9849,\n",
       "             0.9852,     0.98551,     0.98581,     0.98611,     0.98642,     0.98672,     0.98702,     0.98733,     0.98763,     0.98793,     0.98823,     0.98854,     0.98884,     0.98914,     0.98944,     0.98974,     0.99005,     0.99035,     0.99065,     0.99095,     0.99125,     0.99155,     0.99185,\n",
       "            0.99215,     0.99245,     0.99275,     0.99305,     0.99335,     0.99365,     0.99395,     0.99425,     0.99454,     0.99484,     0.99514,     0.99544,     0.99574,     0.99603,     0.99633,     0.99663,     0.99693,     0.99722,     0.99752,     0.99782,     0.99811,     0.99841,     0.99871,\n",
       "              0.999,      0.9993,     0.99959,     0.99989,     0.99445,     0.98543,     0.97625,     0.96691,     0.95739,      0.9477,     0.93782,     0.92775,      0.9175,     0.90704,     0.89638,     0.88552,     0.87443,     0.86312,     0.85159,     0.83981,      0.8278,     0.81553,       0.803,\n",
       "             0.7902,     0.77713,     0.76377,     0.75012,     0.73616,     0.72189,     0.70729,     0.69235,     0.67706,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0033333,   0.0033333,   0.0033333,   0.0033333,    0.011432,    0.011449,    0.011465,    0.011482,    0.011555,    0.013451,    0.021979,    0.043976,    0.076998,     0.10896,      0.1372,     0.16241,     0.18434,     0.19044,     0.19654,     0.22477,     0.24246,     0.25631,     0.26731,\n",
       "            0.27831,     0.30273,      0.3377,     0.34829,     0.35888,     0.36947,     0.38006,     0.39065,     0.40049,     0.40468,     0.40887,     0.41306,     0.41724,     0.42143,     0.42562,     0.42981,       0.434,     0.43819,     0.44238,     0.44657,     0.45076,     0.45495,     0.45914,\n",
       "            0.46333,     0.46751,      0.4717,     0.47589,     0.48008,     0.48427,     0.48846,     0.49265,     0.49684,     0.50775,     0.53935,     0.57095,     0.60255,     0.63415,     0.66575,     0.66724,     0.66783,     0.66842,     0.66901,      0.6696,     0.67019,     0.67078,     0.67137,\n",
       "            0.67197,     0.67256,     0.67315,     0.67374,     0.67433,     0.67492,     0.67551,      0.6761,     0.67669,     0.67728,     0.67787,     0.67846,     0.67905,     0.67964,     0.68023,     0.68083,     0.68142,     0.68201,      0.6826,     0.68319,     0.68378,     0.68437,     0.68496,\n",
       "            0.68555,     0.68614,     0.68673,     0.68732,     0.68791,      0.6885,     0.68909,     0.68969,     0.69028,     0.69087,     0.69146,     0.69205,     0.69264,     0.69323,     0.69382,     0.69441,       0.695,     0.69559,     0.69618,     0.69677,     0.69736,     0.69795,     0.69854,\n",
       "            0.69914,     0.69973,     0.70032,     0.70091,      0.7015,     0.70209,     0.70268,     0.70327,     0.70386,     0.70445,     0.70504,     0.70563,     0.70622,     0.70681,      0.7074,       0.708,     0.70859,     0.70918,     0.70977,     0.71036,     0.71095,     0.71154,     0.71213,\n",
       "            0.71272,     0.71331,      0.7139,     0.71449,     0.71508,     0.71567,     0.71626,     0.71686,     0.71745,     0.71804,     0.71863,     0.71922,     0.71981,      0.7204,     0.72099,     0.72158,     0.72217,     0.72276,     0.72335,     0.72394,     0.72453,     0.72512,     0.72571,\n",
       "            0.72631,      0.7269,     0.72749,     0.72808,     0.72867,     0.72926,     0.72985,     0.73044,     0.73103,     0.73162,     0.73221,      0.7328,     0.73339,     0.73398,     0.73457,     0.73517,     0.73576,     0.73635,     0.73694,     0.73753,     0.73812,     0.73871,      0.7393,\n",
       "            0.73989,     0.74048,     0.74107,     0.74166,     0.74225,     0.74284,     0.74343,     0.74403,     0.74462,     0.74521,      0.7458,     0.74639,     0.74698,     0.74757,     0.74816,     0.74875,     0.74934,     0.74993,     0.75052,     0.75111,      0.7517,     0.75229,     0.75289,\n",
       "            0.75348,     0.75407,     0.75466,     0.75525,     0.75584,     0.75643,     0.75702,     0.75761,      0.7582,     0.75879,     0.75938,     0.75997,     0.76056,     0.76115,     0.76174,     0.76234,     0.76293,     0.76352,     0.76411,      0.7647,     0.76529,     0.76588,     0.76647,\n",
       "            0.76706,     0.76765,     0.76824,     0.76883,     0.76942,     0.77001,      0.7706,      0.7712,     0.77179,     0.77238,     0.77297,     0.77356,     0.77415,     0.77474,     0.77533,     0.77592,     0.77651,      0.7771,     0.77769,     0.77828,     0.77887,     0.77946,     0.78006,\n",
       "            0.78065,     0.78124,     0.78183,     0.78242,     0.78301,      0.7836,     0.78419,     0.78478,     0.78537,     0.78596,     0.78655,     0.78714,     0.78773,     0.78832,     0.78891,     0.78951,      0.7901,     0.79069,     0.79128,     0.79187,     0.79246,     0.79305,     0.79364,\n",
       "            0.79423,     0.79482,     0.79541,       0.796,     0.79659,     0.79718,     0.79777,     0.79837,     0.79896,     0.79955,     0.80014,     0.80073,     0.80132,     0.80191,      0.8025,     0.80309,     0.80368,     0.80427,     0.80486,     0.80545,     0.80604,     0.80663,     0.80723,\n",
       "            0.80782,     0.80841,       0.809,     0.80959,     0.81018,     0.81077,     0.81136,     0.81195,     0.81254,     0.81313,     0.81372,     0.81431,      0.8149,     0.81549,     0.81609,     0.81668,     0.81727,     0.81786,     0.81845,     0.81904,     0.81963,     0.82022,     0.82081,\n",
       "             0.8214,     0.82199,     0.82258,     0.82317,     0.82376,     0.82435,     0.82494,     0.82554,     0.82613,     0.82672,     0.82731,      0.8279,     0.82849,     0.82908,     0.82967,     0.83026,     0.83085,     0.83144,     0.83203,     0.83262,     0.83321,      0.8338,      0.8344,\n",
       "            0.83499,     0.83558,     0.83617,     0.83676,     0.83735,     0.83794,     0.83853,     0.83912,     0.83971,      0.8403,     0.84089,     0.84148,     0.84207,     0.84266,     0.84326,     0.84385,     0.84444,     0.84503,     0.84562,     0.84621,      0.8468,     0.84739,     0.84798,\n",
       "            0.84857,     0.84916,     0.84975,     0.85034,     0.85093,     0.85152,     0.85211,     0.85271,      0.8533,     0.85389,     0.85448,     0.85507,     0.85566,     0.85625,     0.85684,     0.85743,     0.85802,     0.85861,      0.8592,     0.85979,     0.86038,     0.86097,     0.86157,\n",
       "            0.86216,     0.86275,     0.86334,     0.86393,     0.86452,     0.86511,      0.8657,     0.86629,     0.86688,     0.86747,     0.86806,     0.86865,     0.86924,     0.86983,     0.87043,     0.87102,     0.87161,      0.8722,     0.87279,     0.87338,     0.87397,     0.87456,     0.87515,\n",
       "            0.87574,     0.87633,     0.87692,     0.87751,      0.8781,     0.87869,     0.87929,     0.87988,     0.88047,     0.88106,     0.88165,     0.88224,     0.88283,     0.88342,     0.88401,      0.8846,     0.88519,     0.88578,     0.88637,     0.88696,     0.88755,     0.88814,     0.88874,\n",
       "            0.88933,     0.88992,     0.89051,      0.8911,     0.89169,     0.89228,     0.89287,     0.89346,     0.89405,     0.89464,     0.89523,     0.89582,     0.89641,       0.897,      0.8976,     0.89819,     0.89878,     0.89937,     0.89996,     0.90055,     0.90114,     0.90173,     0.90232,\n",
       "            0.90291,      0.9035,     0.90409,     0.90468,     0.90527,     0.90586,     0.90646,     0.90705,     0.90764,     0.90823,     0.90882,     0.90941,        0.91,     0.91059,     0.91118,     0.91177,     0.91236,     0.91295,     0.91354,     0.91413,     0.91472,     0.91531,     0.91591,\n",
       "             0.9165,     0.91709,     0.91768,     0.91827,     0.91886,     0.91945,     0.92004,     0.92063,     0.92122,     0.92181,      0.9224,     0.92299,     0.92358,     0.92417,     0.92477,     0.92536,     0.92595,     0.92654,     0.92713,     0.92772,     0.92831,      0.9289,     0.92949,\n",
       "            0.93008,     0.93067,     0.93126,     0.93185,     0.93244,     0.93303,     0.93363,     0.93422,     0.93481,      0.9354,     0.93599,     0.93658,     0.93717,     0.93776,     0.93835,     0.93894,     0.93953,     0.94012,     0.94071,      0.9413,     0.94189,     0.94249,     0.94308,\n",
       "            0.94367,     0.94426,     0.94485,     0.94544,     0.94603,     0.94662,     0.94721,      0.9478,     0.94839,     0.94898,     0.94957,     0.95016,     0.95075,     0.95134,     0.95194,     0.95253,     0.95312,     0.95371,      0.9543,     0.95489,     0.95548,     0.95607,     0.95666,\n",
       "            0.95725,     0.95784,     0.95843,     0.95902,     0.95961,      0.9602,      0.9608,     0.96139,     0.96198,     0.96257,     0.96316,     0.96375,     0.96434,     0.96493,     0.96552,     0.96611,      0.9667,     0.96729,     0.96788,     0.96847,     0.96906,     0.96966,     0.97025,\n",
       "            0.97084,     0.97143,     0.97202,     0.97261,      0.9732,     0.97379,     0.97438,     0.97497,     0.97556,     0.97615,     0.97674,     0.97733,     0.97792,     0.97851,     0.97911,      0.9797,     0.98029,     0.98088,     0.98147,     0.98206,     0.98265,     0.98324,     0.98383,\n",
       "            0.98442,     0.98501,      0.9856,     0.98619,     0.98678,     0.98737,     0.98797,     0.98856,     0.98915,     0.98974,     0.99033,     0.99092,     0.99151,      0.9921,     0.99269,     0.99328,     0.99387,     0.99446,     0.99505,     0.99564,     0.99623,     0.99683,     0.99742,\n",
       "            0.99801,      0.9986,     0.99919,     0.99978,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,     0.98895,     0.97128,     0.95361,     0.93594,     0.91826,     0.90059,     0.88292,     0.86524,     0.84757,      0.8299,     0.81223,     0.79455,     0.77688,     0.75921,     0.74153,     0.72386,     0.70619,     0.68852,     0.67084,\n",
       "            0.65317,      0.6355,     0.61782,     0.60015,     0.58248,     0.56481,     0.54713,     0.52946,     0.51179,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.8455425\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.84554])\n",
       "names: {0: 'signature'}\n",
       "nt_per_class: array([2])\n",
       "nt_per_image: array([2])\n",
       "results_dict: {'metrics/precision(B)': 0.9720177563261855, 'metrics/recall(B)': 1.0, 'metrics/mAP50(B)': 0.995, 'metrics/mAP50-95(B)': 0.8455425, 'fitness': 0.8455425}\n",
       "save_dir: PosixPath('/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/train35')\n",
       "speed: {'preprocess': 0.44235350000576545, 'inference': 7.527139999993437, 'loss': 0.0035234999984368187, 'postprocess': 1.5278350000045293}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger un modÃ¨le prÃ©-entraÃ®nÃ©\n",
    "model = YOLO(\"yolov8n.pt\")  # Version nano, rapide\n",
    "\n",
    "# EntraÃ®ner sur GPU\n",
    "model.train(\n",
    "    data=\"/home/marco/Projet_du_Fin_DEtude_M2/data.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0  # Utilise le GPU 0 (CUDA)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2abb945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/5 /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/05.jpg: 480x640 1 signature, 47.9ms\n",
      "image 2/5 /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/06.jpg: 480x640 1 signature, 10.5ms\n",
      "image 3/5 /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/14.jpeg: 480x640 1 signature, 9.3ms\n",
      "image 4/5 /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/15.jpeg: 448x640 1 signature, 52.4ms\n",
      "image 5/5 /home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/16.jpeg: 480x640 1 signature, 8.6ms\n",
      "Speed: 2.5ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1m/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'signature'}\n",
       " obb: None\n",
       " orig_img: array([[[148, 145, 137],\n",
       "         [148, 145, 137],\n",
       "         [148, 145, 137],\n",
       "         ...,\n",
       "         [139, 136, 122],\n",
       "         [141, 135, 124],\n",
       "         [140, 134, 123]],\n",
       " \n",
       "        [[143, 140, 132],\n",
       "         [145, 142, 134],\n",
       "         [148, 145, 137],\n",
       "         ...,\n",
       "         [139, 136, 122],\n",
       "         [146, 140, 129],\n",
       "         [144, 138, 127]],\n",
       " \n",
       "        [[141, 138, 130],\n",
       "         [144, 141, 133],\n",
       "         [147, 144, 136],\n",
       "         ...,\n",
       "         [145, 144, 130],\n",
       "         [148, 144, 133],\n",
       "         [146, 142, 131]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 134, 124],\n",
       "         [133, 134, 124],\n",
       "         [135, 136, 126],\n",
       "         ...,\n",
       "         [152, 152, 136],\n",
       "         [160, 154, 141],\n",
       "         [160, 152, 139]],\n",
       " \n",
       "        [[136, 137, 127],\n",
       "         [137, 138, 128],\n",
       "         [138, 139, 129],\n",
       "         ...,\n",
       "         [152, 149, 134],\n",
       "         [160, 152, 139],\n",
       "         [161, 153, 140]],\n",
       " \n",
       "        [[136, 137, 127],\n",
       "         [137, 138, 128],\n",
       "         [136, 137, 127],\n",
       "         ...,\n",
       "         [158, 150, 137],\n",
       "         [163, 154, 144],\n",
       "         [160, 151, 141]]], dtype=uint8)\n",
       " orig_shape: (1589, 2250)\n",
       " path: '/home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/05.jpg'\n",
       " probs: None\n",
       " save_dir: '/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/predict'\n",
       " speed: {'preprocess': 2.6277880000407094, 'inference': 47.93114300002799, 'postprocess': 1.266336000071533},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'signature'}\n",
       " obb: None\n",
       " orig_img: array([[[156, 151, 142],\n",
       "         [155, 150, 141],\n",
       "         [152, 147, 138],\n",
       "         ...,\n",
       "         [156, 147, 137],\n",
       "         [157, 151, 140],\n",
       "         [157, 151, 140]],\n",
       " \n",
       "        [[156, 151, 142],\n",
       "         [156, 151, 142],\n",
       "         [152, 147, 138],\n",
       "         ...,\n",
       "         [153, 144, 134],\n",
       "         [153, 147, 136],\n",
       "         [155, 149, 138]],\n",
       " \n",
       "        [[155, 150, 141],\n",
       "         [155, 150, 141],\n",
       "         [151, 146, 137],\n",
       "         ...,\n",
       "         [149, 143, 132],\n",
       "         [149, 143, 132],\n",
       "         [151, 145, 134]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[156, 151, 142],\n",
       "         [157, 153, 142],\n",
       "         [154, 150, 139],\n",
       "         ...,\n",
       "         [159, 150, 140],\n",
       "         [159, 150, 140],\n",
       "         [160, 151, 141]],\n",
       " \n",
       "        [[156, 152, 141],\n",
       "         [153, 149, 138],\n",
       "         [151, 147, 136],\n",
       "         ...,\n",
       "         [155, 146, 136],\n",
       "         [160, 151, 141],\n",
       "         [163, 154, 144]],\n",
       " \n",
       "        [[153, 149, 138],\n",
       "         [150, 146, 135],\n",
       "         [150, 146, 135],\n",
       "         ...,\n",
       "         [147, 138, 128],\n",
       "         [155, 146, 136],\n",
       "         [158, 149, 139]]], dtype=uint8)\n",
       " orig_shape: (1506, 2090)\n",
       " path: '/home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/06.jpg'\n",
       " probs: None\n",
       " save_dir: '/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/predict'\n",
       " speed: {'preprocess': 2.657596999938505, 'inference': 10.539634999986447, 'postprocess': 1.1427850000700346},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'signature'}\n",
       " obb: None\n",
       " orig_img: array([[[104, 109, 134],\n",
       "         [104, 109, 134],\n",
       "         [103, 107, 132],\n",
       "         ...,\n",
       "         [ 69,  79,  73],\n",
       "         [ 70,  81,  73],\n",
       "         [ 70,  81,  73]],\n",
       " \n",
       "        [[101, 106, 131],\n",
       "         [101, 106, 131],\n",
       "         [101, 105, 130],\n",
       "         ...,\n",
       "         [ 72,  82,  76],\n",
       "         [ 70,  81,  73],\n",
       "         [ 70,  81,  73]],\n",
       " \n",
       "        [[110, 114, 138],\n",
       "         [107, 111, 135],\n",
       "         [100, 104, 128],\n",
       "         ...,\n",
       "         [ 74,  84,  78],\n",
       "         [ 70,  81,  73],\n",
       "         [ 70,  81,  73]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[123, 119, 130],\n",
       "         [125, 121, 132],\n",
       "         [128, 125, 134],\n",
       "         ...,\n",
       "         [112, 118, 113],\n",
       "         [111, 112, 108],\n",
       "         [105, 107, 101]],\n",
       " \n",
       "        [[114, 113, 123],\n",
       "         [117, 116, 126],\n",
       "         [124, 120, 131],\n",
       "         ...,\n",
       "         [112, 118, 113],\n",
       "         [111, 112, 108],\n",
       "         [105, 107, 101]],\n",
       " \n",
       "        [[106, 105, 115],\n",
       "         [111, 110, 120],\n",
       "         [119, 115, 126],\n",
       "         ...,\n",
       "         [113, 119, 114],\n",
       "         [109, 110, 106],\n",
       "         [103, 105,  99]]], dtype=uint8)\n",
       " orig_shape: (688, 978)\n",
       " path: '/home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/14.jpeg'\n",
       " probs: None\n",
       " save_dir: '/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/predict'\n",
       " speed: {'preprocess': 2.6751300000569245, 'inference': 9.34800200002428, 'postprocess': 1.1036259999173126},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'signature'}\n",
       " obb: None\n",
       " orig_img: array([[[125, 124, 114],\n",
       "         [126, 125, 115],\n",
       "         [127, 126, 116],\n",
       "         ...,\n",
       "         [ 72,  70, 116],\n",
       "         [ 84,  83, 125],\n",
       "         [ 87,  88, 126]],\n",
       " \n",
       "        [[124, 123, 113],\n",
       "         [125, 124, 114],\n",
       "         [126, 125, 115],\n",
       "         ...,\n",
       "         [ 81,  80, 124],\n",
       "         [ 95,  94, 136],\n",
       "         [ 99, 100, 138]],\n",
       " \n",
       "        [[125, 125, 113],\n",
       "         [126, 126, 114],\n",
       "         [126, 126, 114],\n",
       "         ...,\n",
       "         [ 98,  97, 137],\n",
       "         [104, 103, 143],\n",
       "         [104, 103, 142]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[107, 121, 117],\n",
       "         [107, 121, 117],\n",
       "         [109, 120, 117],\n",
       "         ...,\n",
       "         [119, 128, 137],\n",
       "         [117, 126, 135],\n",
       "         [121, 133, 139]],\n",
       " \n",
       "        [[107, 121, 117],\n",
       "         [107, 121, 117],\n",
       "         [109, 120, 117],\n",
       "         ...,\n",
       "         [115, 124, 133],\n",
       "         [113, 122, 131],\n",
       "         [121, 133, 139]],\n",
       " \n",
       "        [[108, 122, 118],\n",
       "         [108, 122, 118],\n",
       "         [110, 121, 118],\n",
       "         ...,\n",
       "         [121, 130, 139],\n",
       "         [122, 131, 140],\n",
       "         [120, 132, 138]]], dtype=uint8)\n",
       " orig_shape: (717, 1041)\n",
       " path: '/home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/15.jpeg'\n",
       " probs: None\n",
       " save_dir: '/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/predict'\n",
       " speed: {'preprocess': 2.2337110000307803, 'inference': 52.405582999995204, 'postprocess': 1.1613990000114427},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'signature'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 114, 114],\n",
       "         [115, 115, 115],\n",
       "         [116, 116, 116],\n",
       "         ...,\n",
       "         [133, 130, 116],\n",
       "         [133, 130, 116],\n",
       "         [133, 130, 116]],\n",
       " \n",
       "        [[114, 114, 114],\n",
       "         [115, 115, 115],\n",
       "         [116, 116, 116],\n",
       "         ...,\n",
       "         [136, 133, 119],\n",
       "         [135, 132, 118],\n",
       "         [132, 129, 115]],\n",
       " \n",
       "        [[114, 114, 114],\n",
       "         [115, 115, 115],\n",
       "         [116, 116, 116],\n",
       "         ...,\n",
       "         [139, 136, 122],\n",
       "         [136, 133, 119],\n",
       "         [133, 130, 116]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[122, 119, 114],\n",
       "         [122, 119, 114],\n",
       "         [123, 119, 114],\n",
       "         ...,\n",
       "         [ 95, 106, 114],\n",
       "         [ 95, 106, 114],\n",
       "         [ 94, 107, 115]],\n",
       " \n",
       "        [[126, 123, 118],\n",
       "         [126, 123, 118],\n",
       "         [128, 124, 119],\n",
       "         ...,\n",
       "         [ 99, 110, 118],\n",
       "         [ 99, 110, 118],\n",
       "         [ 93, 106, 114]],\n",
       " \n",
       "        [[129, 125, 120],\n",
       "         [130, 126, 121],\n",
       "         [130, 126, 121],\n",
       "         ...,\n",
       "         [105, 116, 124],\n",
       "         [ 96, 109, 117],\n",
       "         [ 94, 106, 116]]], dtype=uint8)\n",
       " orig_shape: (617, 857)\n",
       " path: '/home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test/16.jpeg'\n",
       " probs: None\n",
       " save_dir: '/home/marco/Projet_du_Fin_DEtude_M2/Models/Model_YOLO/runs/detect/predict'\n",
       " speed: {'preprocess': 2.141867999966962, 'inference': 8.57468100002734, 'postprocess': 1.4006330000029266}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(source=\"/home/marco/Projet_du_Fin_DEtude_M2/Datasets/CIN_data/images/test\", imgsz=640, conf=0.25, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c1e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marco (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
